{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d26c2ab",
   "metadata": {},
   "source": [
    "#### Necessidade de tokens para composição de um dataset de adaptação de domínio\n",
    "\n",
    "* Tokens  : 50.000.000 a 200.000.000\n",
    "* Pág. A4 : 75.000 a 300.000 (500 palavras por página)\n",
    "* Palavras: 37.500.000 a 150.000.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012884d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para ler corpus_0000.jsonl\n",
    "import pandas as pd\n",
    "\n",
    "corpus = pd.read_json('corpus_out/data/shards/corpus_0000.jsonl', lines=True)\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "092897bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# Regex que captura palavras com letras Unicode, dígitos e permite hífens/apóstrofos internos.\n",
    "_WORD_RE = re.compile(\n",
    "    r\"[A-Za-zÀ-ÖØ-öø-ÿ0-9]+(?:['-][A-Za-zÀ-ÖØ-öø-ÿ0-9]+)*\",\n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "def count_words(text: str) -> Tuple[Dict[str, int], int]:\n",
    "    \"\"\"\n",
    "    Conta palavras em `text`.\n",
    "\n",
    "    Args:\n",
    "        text: string com o conteúdo a ser analisado.\n",
    "\n",
    "    Returns:\n",
    "        (freqs, total)\n",
    "        - freqs: dict onde as chaves são palavras em minúsculas e os valores são\n",
    "                 as ocorrências (int).\n",
    "        - total: número total de palavras encontradas (int).\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {}, 0\n",
    "\n",
    "    # Extrai palavras e normaliza para minúsculas\n",
    "    words = [w.lower() for w in _WORD_RE.findall(text)]\n",
    "    freqs = dict(Counter(words))\n",
    "    total = sum(freqs.values())\n",
    "    return freqs, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d3cb9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos: 105\n",
      "Total de palavras no dataset: 331185\n"
     ]
    }
   ],
   "source": [
    "# Contar numero de palavras em cada documento\n",
    "corpus['word_count'] = corpus['text'].apply(lambda x: count_words(x)[1])\n",
    "\n",
    "#corpus['text'].head()\n",
    "#corpus[['word_count']].head()\n",
    "total_words = corpus['word_count'].fillna(0).sum()\n",
    "\n",
    "print(\"Número de documentos:\", corpus.shape[0])\n",
    "print(\"Total de palavras no dataset:\", total_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
